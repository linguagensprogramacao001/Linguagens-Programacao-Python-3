{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "horizontal-increase",
   "metadata": {},
   "source": [
    "# 1. Variáveis e Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dangerous-radical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joao'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'joao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proper-romania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "better-democrat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tired-article",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True  # ou False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incorporate-recipe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42+3.14j)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 + 3.14j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-exposure",
   "metadata": {},
   "source": [
    "## Função Type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "failing-elimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('joao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "royal-toner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "korean-processor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "welsh-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "geological-biology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complex"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(42 + 3.14j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-gregory",
   "metadata": {},
   "source": [
    "## Referênciando na memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mature-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALUNO = 'joao'\n",
    "\n",
    "RESPOSTA = 42\n",
    "\n",
    "PI = 3.14\n",
    "\n",
    "COMPLEXO = 42 + 3.14j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dressed-asthma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joao'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALUNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "crude-third",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESPOSTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rational-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unsigned-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOLEANO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afraid-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42+3.14j)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMPLEXO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-upset",
   "metadata": {},
   "source": [
    "## Função id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "insured-cocktail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2578090143024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(ALUNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ultimate-nickname",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140735761759296"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(RESPOSTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "removed-planner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2578089896752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "proper-playing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140735761475440"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(BOOLEANO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "inclusive-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140735761475408"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fatty-sampling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2578090307728"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(COMPLEXO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-scroll",
   "metadata": {},
   "source": [
    "## Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "conservative-treatment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sized-cedar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.14'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "occasional-oliver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(str(PI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "failing-wright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "young-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(int(PI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "worldwide-civilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b101010'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "accepted-armstrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x2a'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-easter",
   "metadata": {},
   "source": [
    "### Observação:\n",
    "O prefixo 0b e 0x indica a base utilizada, respectivamente 2 e 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "smart-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PI = RESPOSTA\n",
    "PI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
